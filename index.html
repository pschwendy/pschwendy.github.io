<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Peter Schwendeman</title>
  <style>
    body {
      font-family: monospace;
      margin: 40px;
      line-height: 1.4;
      font-size: 15px;
      max-width: 900px;
    }
    img.profile {
      width: 240px;
      border: 1px solid #ccc;
      margin-left: 30px;
      float: right;
    }
    h2 {
      margin-top: 30px;
    }
    a {
      color: black;
      text-decoration: underline;
    }
  </style>
</head>

<body>

<h1>Peter Schwendeman</h1>

<p>
    Computer Science & Math/Physics (minor) · University of Michigan <br>
<a href="https://www.linkedin.com/in/peter-schwendeman-523014256">LinkedIn</a> ·
<a href="https://github.com/pschwendy">GitHub</a> · <a href="https://scholar.google.com/citations?user=T4_anL4AAAAJ&hl=en">Google Scholar</a>
</p>

<hr>

<h2>About</h2>

<img src="./assets/me.JPG" alt="Photo of Peter" class="profile">

<p>
My broader research interests are fairly broad, but roughly lie in AI for science,   
synthetic data distributions, and reinforcement learning using learned verifiers (aka also synthetic data distributions).  
I’m especially interested in how we can use large-scale neural models and synthetic
data to uncover hidden structure in complex natural systems—biological or otherwise.
</p>

<p>
I am currently an undergraduate researcher in Michigan Medicine under <b>Professor Yuanfang Guan</b>. Much of my recent work focuses on learning how individual neurons encode visual information,
recovering stimuli from neural activity, and using generative modeling to explore the distribution of biological representations.  
</p>
<p>
Last summer, I was a research scientist intern at <b>Sakana AI</b>, where I worked with the amazing <b>Dr. Yujin Tang</b> on
reinforcement learning and evolutionary approaches for structured collaboration among LLM agents.
</p>

<p>
Before any of this AI/ML stuff, I was a rookie in <b>Prof. Sharon Glotzer’s lab</b> at the University of Michigan Department of Chemical Engineering, where I worked on
GPU-accelerated molecular dynamics simulations. In high school, I was also a part-time software developer at Deque Systems.
</p>

<hr>

<h2>Publications/Papers</h2>
<b>2 more coming soon!</b> (in review at ICLR — redacted for anonymous review)
<p>
    <b>Learnable Diffusion Framework for Mouse V1 Neural Decoding</b><br>
    K. Deng*, <b>P. S. Schwendeman*</b>, Y. Guan. In review at Advanced Science.  
    <a href="https://pschwendy.github.io/assets/neural_decoding_paper.pdf">(current draft)</a>
    </p>

<p>
<b>Effect of PLGA raw materials on in vitro and in vivo performance of drug-loaded microspheres.</b><br>
D. Liang, J. Walker, <b>P. S. Schwendeman</b>, et al. Drug Delivery and Translational Research (2024).  
<a href="https://doi.org/10.1007/s13346-024-01577-y">doi</a>
</p>

<p>
<b>Predicting Single Neuron Responses of the Primary Visual Cortex with Deep Learning Model.</b><br>
K. Deng, <b>P. S. Schwendeman</b>, Y. Guan. Advanced Science (2024).  
<a href="https://doi.org/10.1002/advs.202305626">doi</a>
</p>

<p>
<b>Unified memory in HOOMD-blue improves node-level strong scaling.</b><br>
J. Glaser, <b>P. S. Schwendeman</b>, et al. Computational Materials Science (2020).  
<a href="https://doi.org/10.1016/j.commatsci.2019.109359">doi</a>
</p>

<hr>

<h2>Current Research Directions</h2>
I try to focus on research directions that may teach us something useful (as opposed to just raising metrics).
Here are some research directions I hope to wrap up by the end of my undergrad!
<p>
<b>The Multi-Agent Debate Game for Reinforcement Learning.</b> 
Training LLMs through reinforcement learning with priviledged information inside a toy debate game. We want to see if LLMs can learn from natural language dynamics 
when priviledged information—e.g., an answer to a math problem—is partially available. We want to learn how effective approaches like natural language "games" can be towards reasoning on hard-to-verify problems!
<!-- <a href="TODO: insert proposal link">[proposal]</a> -->
</p>

<p>
<b>Can we optimize artificial neural networks using in vitro brain dynamics?</b> We apply meta-learning to 
utilize single neuron response recordings as a training mechanism for neural networks in performing basic tasks like image classification (on mouse stimulus).
The hope is both to create "brain-distilled optimizers" and possibly use symbolic learning to uncover something about the learning dynamics of mice brains.
<!-- <a href="TODO: insert proposal link">[proposal]</a> -->
</p>

<p>
<b>Uncovering the mouse connectome from stimulus-response pairs.</b> We attempt to use video stimulus-neuron response pairs to train a foundation model capable of predicting <b>physical connectivity</b> in the mouse brain (specifically V1).
This project is based on the challenge of mapping out the connectome of brains and its hopes for neuroscientific discovery and therapeutics.
<!-- <a href="TODO: insert proposal link">[proposal]</a> -->
</p>

<h2>Teaching</h2>

<p>At Michigan, I TA for <b>EECS 445</b> (Introduction to Machine Learning)! (W24, F25)</p>

<h2>Some Fun Side Projects</h2>

<p>
<b>Poker AI</b> — Deep RL agent approaching SOTA exploitability.  
<a href="https://github.com/pschwendy/poker">[code]</a>
</p>

<p>
<b>SugarSense</b> — State space model for forecasting blood glucose 2 hours ahead (0.95 corr).  
<a href="https://github.com/pschwendy/SugarSense">[code]</a>
</p>

<hr>

<h2>CV</h2>
<p>
<a href="https://pschwendy.github.io/assets/cv.pdf">See my CV</a>
</p>

<hr>

<p>Last updated: 2025</p>

</body>
</html>
